In this session, we are going to explore the idea of validation by testing.
Even though our main focus will be testing, we'll also tackle other validation methods such as fuzzing and symbolic execution.
Before diving into how we can do testing on Unikraft, let's first focus on several key concepts that are used when talking about testing.

There are three types of testing: unit testing, integration testing and end-to-end testing.
To better understand the difference between them, we will look over an example of a webshop.
If we're testing the whole workflow (creating an account, logging in, adding products to a cart, placing an order) we will call this **end-to-end testing**.
Our shop also has an analytics feature that allows us to see a couple of data points such as: how many times an article was clicked on, how much time did a user look at it and so on.
To make sure the inventory module and the analytics module are working correctly (a counter in the analytics module increases when we click on a product), we will be writing **integration tests**.
Our shop also has at least an image for every product which should maximize when we're clicking on it. To test this, we would write a **unit test**.

Running the test suite after each change is called **regression testing**. **Automatic testing** means that the tests are run and verified automatically. **Automated regression testing** is the best practice in software engineering.

One of the key metrics used in testing is **code coverage**.
This is used to measure the percentage of code that is executed during a test suite run.

There are three common types of coverage:
* **Statement coverage**: the percentage of code statements that are run during the testing
* **Branch coverage**: the percentage of branches executed during the testing (e.g. if or while)
* **Path coverage**: the percentage of paths executed during the testing

We'll now go briefly over two other validation techniques: fuzzing and symbolic execution.
